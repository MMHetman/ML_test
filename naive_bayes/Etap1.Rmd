---
title: "Podstawy maszynowego uczenia na przykładzie klasyfikacji tekstu"
subtitle: "Sztuczna Inteligencja i Inżyniera Wiedzy. Ćwiczenie 4"
author: "Michał Hetmańczuk"
date: "27 05 2020"
output: pdf_document
---
Sprawozdanie powstało jak dokument typu R Markdown.
```{r setup, include=FALSE}
library(utils)
library(readtext)
library(stringr)
library(tm)
library(SnowballC)
library(wordcloud)
library(quanteda)
library(fastNaiveBayes)
library(tree)
library(gdata)
```
# Etap 1
## Data processing
W pierwszej kolejności rozpakowano piliki zip.
```{r include=FALSE}
unzip(zipfile = ".\\wiki_train_34_categories_data.zip", exdir = ".\\extdata\\train")
unzip(zipfile = ".\\wiki_test_34_categories_data.zip", exdir = ".\\extdata\\train")
```
Następnie umieszczono zawartość plików w strukturze danych typu Data Frame. Z nazwy pliku wyekstrahowano kategorię dokumentu. Referencja na tak utworzoną strukturę. została nazwana 'texts_df'.
```{r include=FALSE}
texts_df = data.frame(category = factor(), text = character())
files <- list.files(path=".\\extdata\\train", pattern="*.txt", full.names=TRUE, recursive=FALSE)
for(x in files) {
    if (str_detect(x, 'metadata') | str_detect(x, 'license')) {
      next()
    }
    t <- readtext(file = x, encoding = 'utf-8')
    obs <- data.frame((strsplit(t[,1],'_')[[1]][1]), t[,2], stringsAsFactors = FALSE)
    names(obs) <- c('category', 'text')
    texts_df <- rbind(texts_df, obs)
}
texts_df$category <- factor(texts_df$category)
```
Opis struktury:
```{r}
str(texts_df, vec.len = 0)
levels(texts_df$category)
```
Aby ujednolcić tekst oraz wstępnie usunąć potencjalnie zbędne cechy, dane zostały wyczyszczone poprzez usunięcie: wielkich liter, liczb, znaków interpunkcyjnych, zbędnych białych znaków oraz wyrazów ze stop-listy (plik stopwords.txt z polską stop-listą został zaczerpnięty z https://github.com/bieli/stopwords/blob/master/polish.stopwords.txt). Aby wykorzystać w tym celu funkcję tm_map, zawartość dokumentów umieszczono w przeznaczonej do tego strukturze - VCorpus (taki typ danych jest obsługiwany przez tm_map).
```{r warning=FALSE}
text_labels <- texts_df$category
text_corpus <- VCorpus(VectorSource(texts_df$text))
text_corpus_clean <- text_corpus %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
stopwords.pl <- readLines(".\\stopwords.txt", encoding = 'UTF-8')
text_corpus_clean <- tm_map(text_corpus_clean, removeWords, stopwords.pl)
```
Wykorzystując tak wyczyszczone korpusy dokumentów utworzono macierz pojęć, zawierającą częstotliwości występowania danego pojęcia w danym dokumencie. 
```{r}
text_dtm <- DocumentTermMatrix(text_corpus_clean)
text_dtm
```
Przykładowe wizualizacje przygotowanych danych. 
Kategorie: "Albania", "Choroby", "Astronautyka" 
```{r echo=FALSE, warning=FALSE, out.width="33%"}
wordcloud(text_corpus_clean[which(text_labels == 'Albania')], min.freq = 50, random.order = FALSE)

wordcloud(text_corpus_clean[which(text_labels == 'Choroby')], min.freq = 50, random.order = FALSE)

wordcloud(text_corpus_clean[which(text_labels == 'Astronautyka')], min.freq = 50, random.order = FALSE)

``` 


## Propozycja metody selekcji cech i implementacji modeli
Ze względu na fakt, iż mamy do czynienia z szukaniem zależności między dwoma kategorycznymi zmiennym, selekcja cech zostanie przeprowadzona z wykorzystnaiem testów $\ X^2$.
Implementacja klaysfikatora Naiwnego Bayesa zostanie zaczerpnięta z biblioteki "fastNaiveBayes". Biblioteka tak obsłguje wszystkie rodzaje klasyfikatora (Bernoulli, Gaussiam, Mulitnomial), co może być bardzo przydatne z perspektywy przeprowadzania badań. Wykorzystana zostanie również implementacja drzewa decyzyjnego z pakietu "tree".

## Naive-Bayes
Model został zaimplementowany w następujący sposób: Wykonany trening z wykorzystaniem 10-krotnej walidacji krzyżowej, wywołujać funkcję z wybranej wcześniej biblioteki fastNaiveBayes
```{r include=FALSE}
fs_dfm <- dfm(corpus(text_corpus_clean))
```
```{r include=FALSE}
performNaiveBayes <- function(nfeatures, laplace){
  
  models = vector()
  accs = vector()
  chi2vals <- dfm_group(fs_dfm) %>%
  textstat_keyness(measure = "chi2")
  chi2vals$chi2 <- abs(chi2vals$chi2)
  chi2vals <- chi2vals[order(-chi2vals$chi2), ]
  dfmTop <- dfm_select(fs_dfm, chi2vals$feature[1:nfeatures])
  freq_mat <- as.matrix(dfmTop)
  
  freq_mat <- as.matrix(dfmTop)
  
  indices <- sample(1:nrow(texts_df))
  indices <-split(indices, 1:10)
  
  for(i in 1:10) {
    test_indices = indices[[i]]
    train_indices = unlist(indices[-i], use.names = FALSE)
    
    model <- fnb.multinomial(freq_mat[train_indices,], text_labels[train_indices], laplace = laplace)
    pred <- predict(model, freq_mat[test_indices,])
    acc = sum(pred == text_labels[test_indices])/length(test_indices)
    
    models = c(models, model)
    accs = c(accs, acc)
  }
  
  best = which.max(accs)
  return(list(models[best], accs[best]))
}

```
### Badanie wpływu liczby wybranych cech na wynik działania modelu
```{r, warning=FALSE}
nfeatures = seq(100, 5000, by = 100)
results = vector()

for(i in nfeatures){
  results = c(results, performNaiveBayes(i, 0)[2])
}

plot(nfeatures, results)
```
```{r, warning=FALSE}
nfeatures = seq(1000, 2000, by = 10)
results = vector()

for(i in nfeatures){
  results = c(results, performNaiveBayes(i, 0)[2])
}

plot(nfeatures, results)
```
### Badanie wpływu współczynnik wygładzania laplace'a na wynik działa modelu

```{r, warning=FALSE}
laplaces = seq(0,10, by = 0.1)
results = vector()

for(i in laplaces){
  results = c(results, performNaiveBayes(1350, i)[2])
}

plot(laplaces, results)
```

### Wyniki badań
Najlepsze wyniki osiągnięto dla 1350 cech oraz współczynnika 0.5
```{r, warning=FALSE}
results = vector()
for(i in 1:10){
  results = c(results, performNaiveBayes(1350, 0.5)[2])
}

mean(unlist(results, use.names=FALSE))
```

## Decision tree
Wybrana biblioteka ma już wbudowaną 10-krotną walidację krzyżową
Uwaga! Niestety ze względu na nieznane wcześniej ograniczenia wybranej biblioteki - można wykorzystać maksymalnie 32 kategorie. Odrzucono dwie kategorie oraz opisywane przez nie dokumenty.
```{r}
texts_df = data.frame(category = factor(), text = character())
files <- list.files(path=".\\extdata\\train", pattern="*.txt", full.names=TRUE, recursive=FALSE)
for(x in files) {
    if (str_detect(x, 'metadata') | str_detect(x, 'license') | str_detect(x, 'Albania') | str_detect(x, 'Zydzi')) {
      next()
    }
    t <- readtext(file = x, encoding = 'utf-8')
    obs <- data.frame((strsplit(t[,1],'_')[[1]][1]), t[,2], stringsAsFactors = FALSE)
    names(obs) <- c('category', 'text')
    texts_df <- rbind(texts_df, obs)
}
texts_df$category <- factor(texts_df$category)

text_labels <- texts_df$category
text_corpus <- VCorpus(VectorSource(texts_df$text))
text_corpus_clean <- text_corpus %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)

fs_dfm <- dfm(corpus(text_corpus_clean))

chi2vals <- dfm_group(fs_dfm) %>%
textstat_keyness(measure = "chi2")
chi2vals$chi2 <- abs(chi2vals$chi2)
chi2vals <- chi2vals[order(-chi2vals$chi2), ]
dfmTop <- dfm_select(fs_dfm, chi2vals$feature[1:1000])

texts_freq_df <- as.data.frame(dfmTop)
texts_freq_df$category <- as.factor(text_labels)
colnames(texts_freq_df) <- make.names(colnames(texts_freq_df))
texts_freq_df <- texts_freq_df[,!duplicated(colnames(texts_freq_df))] 
texts_freq_df <- texts_freq_df[,!(names(texts_freq_df) == '-')] 
colnames(texts_freq_df) <- make.names(colnames(texts_freq_df))
    
model <- tree(category ~ . , data = texts_freq_df, na.action = na.pass, control = tree.control(nobs = nrow(texts_freq_df)), mincut =2, minsize = 5)
summary(model)

pred <- predict(model, texts_freq_df[,!names(texts_freq_df) == 'category'], type = 'class')

sum(pred == texts_freq_df$category)/length(pred)


```






